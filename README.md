# Scalable ETL Pipeline for E-Commerce Data
<div align="center">
</div>

## About The Project

The Scalable ETL Pipeline for E-Commerce Data is designed to automate the process of extracting, transforming, and loading (ETL) e-commerce data. It ensures efficient data processing for analytical and operational use.

## Functionality 
 
1. Extract data from APIs and databases.
2. Transform data by cleaning and normalizing it.
3. Load the processed data into a SQLite database.
4. Dockerized for easy deployment.
5. Supports workflow automation** via Apache Airflow.

## Modules In The System

1. Extract data from different sources.
2. Transform and clean data.
3. Load structured data into a database.
4. Automate ETL process using Apache Airflow.

## Benefits Of The System

- Automates the ETL process for e-commerce data.
- Ensures structured and clean data storage.
- Enhances data processing efficiency for analytics.

## Created & Maintained By
 [HARSHINI CHINTAPALLY](https://github.com/Harshini0201) <br/>



## Getting Started


To clone the repository on your computer:
```bash
git clone https://github.com/your-repo/scalable-etl-pipeline.git
cd scalable-etl-pipeline
 ```
To install dependencies:
```bash
pip install -r requirements.txt
```
To run the project:
```bash
python main.py
```

## Tools Used

EDITOR:
 - [VISUAL STUDIO CODE](https://code.visualstudio.com/)
 
FRONT-END:
 - [REACT](https://reactjs.org/)
 
BACK-END:
 Python (Flask/FastAPI for API integration)  
 
DATABASE:
SQLite/PostgreSQL  
